{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115ffcad-1751-45ce-bbf5-02c5efcfa6c1",
   "metadata": {},
   "source": [
    "### Connection to MinIO/S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a948dfa-dffb-4a3f-ae4e-8bde5e9c55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = 'http://server:9000'\n",
    "SPARK_MASTER = \"spark://server:7077\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d87fa-455f-403d-af87-cd2343c5ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName('Quantum Pipeline Feature Processing')\n",
    "    .master(SPARK_MASTER)\n",
    "    .config('spark.hadoop.fs.s3a.endpoint', S3)\n",
    "    .config('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "    .config('spark.hadoop.fs.s3a.access.key', os.environ.get('MINIO_ACCESS_KEY'))\n",
    "    .config('spark.hadoop.fs.s3a.secret.key', os.environ.get('MINIO_SECRET_KEY'))\n",
    "    .config('spark.hadoop.fs.s3a.path.style.access', 'true')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e0839-d8db-4df7-a04e-084c79e133e7",
   "metadata": {},
   "source": [
    "## Read the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378925b5-f86d-4eea-98a6-ea4c0be57961",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = 's3a://local-vqe-results/experiments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5210a0-4b4b-4fc6-8a48-70f5be345d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4j.java_gateway import java_import\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "java_import(spark._jvm, \"org.apache.hadoop.fs.FileSystem\")\n",
    "java_import(spark._jvm, \"org.apache.hadoop.fs.Path\")\n",
    "java_import(spark._jvm, \"org.apache.hadoop.conf.Configuration\")\n",
    "\n",
    "def list_available_topics():\n",
    "    \"\"\"List available topic names under experiments/\"\"\"\n",
    "\n",
    "    fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(\n",
    "        spark._jvm.java.net.URI.create(S3_BUCKET), spark._jsc.hadoopConfiguration()\n",
    "    )\n",
    "\n",
    "    path = spark._jvm.org.apache.hadoop.fs.Path(S3_BUCKET)\n",
    "    \n",
    "    if fs.exists(path) and fs.isDirectory(path):\n",
    "        return [\n",
    "            f.getPath().getName()\n",
    "            for f in fs.listStatus(path) if f.isDirectory()\n",
    "        ]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ccb08b-6dab-4929-9772-dbf460e5fe66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "available_topics = list_available_topics()\n",
    "print(\"Available Topics:\", available_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855de497-5750-42de-9ae7-e4162031705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def read_avro_by_topic(topic_name):\n",
    "    \"\"\"Read Avro files from a specific topic's directory\"\"\"\n",
    "    topic_base_path = f\"{S3_BUCKET}{topic_name}/\"\n",
    "    topic_path = f\"{topic_base_path}partition=*/\"\n",
    "    df = spark.read.format(\"avro\").load(topic_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd2a118-eaa1-4510-a3a5-4b5947d38196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_avro_by_topic(available_topics[0])\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030392b-0cd2-469a-9ea9-becfc2dea7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, size, expr, lit, monotonically_increasing_id\n",
    "\n",
    "base_df = df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"basis_set\"),\n",
    "    col(\"vqe_result.initial_data\").alias(\"initial_data\"),\n",
    "    col(\"vqe_result.iteration_list\").alias(\"iteration_list\"),\n",
    "    col(\"vqe_result.minimum\").alias(\"minimum_energy\"),\n",
    "    col(\"vqe_result.optimal_parameters\").alias(\"optimal_parameters\"),\n",
    "    col(\"vqe_result.maxcv\").alias(\"maxcv\"),\n",
    "    col(\"vqe_result.minimization_time\").alias(\"minimization_time\"),\n",
    "    col(\"hamiltonian_time\"),\n",
    "    col(\"mapping_time\"),\n",
    "    col(\"vqe_time\"),\n",
    "    col(\"total_time\"),\n",
    "    col(\"molecule.molecule_data\").alias(\"molecule_data\")\n",
    ")\n",
    "\n",
    "df_molecule = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"molecule_data.symbols\").alias(\"atom_symbols\"),\n",
    "    col(\"molecule_data.coords\").alias(\"coordinates\"),\n",
    "    col(\"molecule_data.multiplicity\").alias(\"multiplicity\"),\n",
    "    col(\"molecule_data.charge\").alias(\"charge\"),\n",
    "    col(\"molecule_data.units\").alias(\"coordinate_units\"),\n",
    "    col(\"molecule_data.masses\").alias(\"atomic_masses\")\n",
    ")\n",
    "\n",
    "df_ansatz = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"initial_data.ansatz\").alias(\"ansatz\"),\n",
    "    col(\"initial_data.ansatz_reps\").alias(\"ansatz_reps\")\n",
    ")\n",
    "\n",
    "df_metrics = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"basis_set\"),\n",
    "    col(\"hamiltonian_time\"),\n",
    "    col(\"mapping_time\"),\n",
    "    col(\"vqe_time\"),\n",
    "    col(\"total_time\"),\n",
    "    col(\"minimization_time\"),\n",
    "    (col(\"hamiltonian_time\") + col(\"mapping_time\") + col(\"vqe_time\")).alias(\"computed_total_time\")\n",
    ")\n",
    "\n",
    "df_vqe = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"basis_set\"),\n",
    "    col(\"initial_data.backend\").alias(\"backend\"),\n",
    "    col(\"initial_data.num_qubits\").alias(\"num_qubits\"),\n",
    "    col(\"initial_data.optimizer\").alias(\"optimizer\"),\n",
    "    col(\"initial_data.noise_backend\").alias(\"noise_backend\"),\n",
    "    col(\"initial_data.default_shots\").alias(\"default_shots\"),\n",
    "    col(\"initial_data.ansatz_reps\").alias(\"ansatz_reps\"),\n",
    "    col(\"minimum_energy\"),\n",
    "    col(\"maxcv\"),\n",
    "    size(col(\"iteration_list\")).alias(\"total_iterations\")\n",
    ")\n",
    "\n",
    "df_initial_parameters = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"initial_data.backend\").alias(\"backend\"),\n",
    "    col(\"initial_data.num_qubits\").alias(\"num_qubits\"),\n",
    "    explode(col(\"initial_data.initial_parameters\")).alias(\"initial_parameter_value\")\n",
    ")\n",
    "\n",
    "df_initial_parameters = df_initial_parameters.withColumn(\n",
    "    \"parameter_index\", \n",
    "    expr(\"row_number() over (partition by molecule_id, backend, num_qubits order by 1) - 1\")\n",
    ")\n",
    "\n",
    "df_optimal_parameters = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"initial_data.backend\").alias(\"backend\"),\n",
    "    col(\"initial_data.num_qubits\").alias(\"num_qubits\"),\n",
    "    explode(col(\"optimal_parameters\")).alias(\"optimal_parameter_value\")\n",
    ")\n",
    "\n",
    "df_optimal_parameters = df_optimal_parameters.withColumn(\n",
    "    \"parameter_index\", \n",
    "    expr(\"row_number() over (partition by molecule_id, backend, num_qubits order by 1) - 1\")\n",
    ")\n",
    "\n",
    "df_iterations = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"initial_data.backend\").alias(\"backend\"),\n",
    "    col(\"initial_data.num_qubits\").alias(\"num_qubits\"),\n",
    "    explode(col(\"iteration_list\")).alias(\"iteration\")\n",
    ").select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"backend\"),\n",
    "    col(\"num_qubits\"),\n",
    "    col(\"iteration.iteration\").alias(\"iteration_step\"),\n",
    "    col(\"iteration.result\").alias(\"iteration_energy\"),\n",
    "    col(\"iteration.std\").alias(\"energy_std_dev\")\n",
    ")\n",
    "\n",
    "df_iteration_parameters = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"initial_data.backend\").alias(\"backend\"),\n",
    "    col(\"initial_data.num_qubits\").alias(\"num_qubits\"),\n",
    "    explode(col(\"iteration_list\")).alias(\"iteration\")\n",
    ").select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"backend\"),\n",
    "    col(\"num_qubits\"),\n",
    "    col(\"iteration.iteration\").alias(\"iteration_step\"),\n",
    "    explode(col(\"iteration.parameters\")).alias(\"parameter_value\")\n",
    ")\n",
    "\n",
    "df_iteration_parameters = df_iteration_parameters.withColumn(\n",
    "    \"parameter_index\", \n",
    "    expr(\"row_number() over (partition by molecule_id, backend, num_qubits, iteration_step order by 1) - 1\")\n",
    ")\n",
    "\n",
    "df_hamiltonian = base_df.select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"initial_data.backend\").alias(\"backend\"),\n",
    "    explode(col(\"initial_data.hamiltonian\")).alias(\"hamiltonian_term\")\n",
    ").select(\n",
    "    col(\"molecule_id\"),\n",
    "    col(\"backend\"),\n",
    "    col(\"hamiltonian_term.label\").alias(\"term_label\"),\n",
    "    col(\"hamiltonian_term.coefficients.real\").alias(\"coeff_real\"),\n",
    "    col(\"hamiltonian_term.coefficients.imaginary\").alias(\"coeff_imag\")\n",
    ")\n",
    "\n",
    "df_hamiltonian = df_hamiltonian.withColumn(\n",
    "    \"term_index\", \n",
    "    expr(\"row_number() over (partition by molecule_id, backend order by term_label) - 1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515b74d-2ee9-44f2-a624-6b8a7308e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "test_df = spark.range(1000).repartition(10)\n",
    "start_time = time.time()\n",
    "count = test_df.count()\n",
    "duration = time.time() - start_time\n",
    "print(f\"Count: {count}, Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e9c05-b197-424c-a960-f15ae27df69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_molecule.show(3, truncate=False)\n",
    "df_metrics.show(3, truncate=False)\n",
    "df_iterations.show(3, truncate=False)\n",
    "df_iteration_parameters.show(3, truncate=False)\n",
    "df_hamiltonian.show(3, truncate=False)\n",
    "\n",
    "df_vqe.show(3, truncate=False)\n",
    "df_initial_parameters.show(3, truncate=False)\n",
    "df_optimal_parameters.show(3, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
